{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hj7-HI8CIiXW",
    "outputId": "26e07d09-9b52-4881-9c1b-ac609ff93a2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8MZWBb0InK-",
    "outputId": "982b26ed-1f0c-442d-f461-fee936222f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/boudinfl/pke.git\n",
      "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-5oim_osn\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/boudinfl/pke.git /tmp/pip-req-build-5oim_osn\n",
      "  Resolved https://github.com/boudinfl/pke.git to commit f2d4f5d2252c64d23defccd32fdac8809cfd7ce0\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (3.8.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (1.24.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (1.2.2)\n",
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (1.3.6)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (0.18.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (1.2.0)\n",
      "Requirement already satisfied: spacy>=3.2.3 in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (3.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.10.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.1.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (8.1.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (67.6.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.28.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.65.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (6.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.4)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.7.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->pke==2.0.0) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->pke==2.0.0) (2022.10.31)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->pke==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.7.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/boudinfl/pke.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_loXbF9qJI2-",
    "outputId": "1b79e00c-c584-4583-e05b-9555c8329b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-03-17 18:01:38.661004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-17 18:01:38.661164: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-17 18:01:38.661188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-17 18:01:40.586296: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.6)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FS3_Q0JHL6KU",
    "outputId": "f0c83526-432e-4758-a839-6a188230f6de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting bert-extractive-summarizer\n",
      "  Using cached bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting numpy>=1.17.3\n",
      "  Using cached numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.10.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-67.6.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Using cached thinc-8.1.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.10.0-py3-none-any.whl (9.9 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Installing collected packages: tokenizers, cymem, wasabi, urllib3, typing-extensions, tqdm, threadpoolctl, spacy-loggers, spacy-legacy, smart-open, setuptools, regex, pyyaml, packaging, numpy, murmurhash, MarkupSafe, langcodes, joblib, idna, filelock, click, charset-normalizer, certifi, catalogue, typer, srsly, scipy, requests, pydantic, preshed, jinja2, blis, scikit-learn, pathy, huggingface-hub, confection, transformers, thinc, spacy, bert-extractive-summarizer\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: cymem\n",
      "    Found existing installation: cymem 2.0.7\n",
      "    Uninstalling cymem-2.0.7:\n",
      "      Successfully uninstalled cymem-2.0.7\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 1.1.1\n",
      "    Uninstalling wasabi-1.1.1:\n",
      "      Successfully uninstalled wasabi-1.1.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.15\n",
      "    Uninstalling urllib3-1.26.15:\n",
      "      Successfully uninstalled urllib3-1.26.15\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.1.0\n",
      "    Uninstalling threadpoolctl-3.1.0:\n",
      "      Successfully uninstalled threadpoolctl-3.1.0\n",
      "  Attempting uninstall: spacy-loggers\n",
      "    Found existing installation: spacy-loggers 1.0.4\n",
      "    Uninstalling spacy-loggers-1.0.4:\n",
      "      Successfully uninstalled spacy-loggers-1.0.4\n",
      "  Attempting uninstall: spacy-legacy\n",
      "    Found existing installation: spacy-legacy 3.0.12\n",
      "    Uninstalling spacy-legacy-3.0.12:\n",
      "      Successfully uninstalled spacy-legacy-3.0.12\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 6.3.0\n",
      "    Uninstalling smart-open-6.3.0:\n",
      "      Successfully uninstalled smart-open-6.3.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 67.6.0\n",
      "    Uninstalling setuptools-67.6.0:\n",
      "      Successfully uninstalled setuptools-67.6.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2022.10.31\n",
      "    Uninstalling regex-2022.10.31:\n",
      "      Successfully uninstalled regex-2022.10.31\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "  Attempting uninstall: murmurhash\n",
      "    Found existing installation: murmurhash 1.0.9\n",
      "    Uninstalling murmurhash-1.0.9:\n",
      "      Successfully uninstalled murmurhash-1.0.9\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.2\n",
      "    Uninstalling MarkupSafe-2.1.2:\n",
      "      Successfully uninstalled MarkupSafe-2.1.2\n",
      "  Attempting uninstall: langcodes\n",
      "    Found existing installation: langcodes 3.3.0\n",
      "    Uninstalling langcodes-3.3.0:\n",
      "      Successfully uninstalled langcodes-3.3.0\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.2.0\n",
      "    Uninstalling joblib-1.2.0:\n",
      "      Successfully uninstalled joblib-1.2.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.10.0\n",
      "    Uninstalling filelock-3.10.0:\n",
      "      Successfully uninstalled filelock-3.10.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.3\n",
      "    Uninstalling click-8.1.3:\n",
      "      Successfully uninstalled click-8.1.3\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.1.0\n",
      "    Uninstalling charset-normalizer-3.1.0:\n",
      "      Successfully uninstalled charset-normalizer-3.1.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Uninstalling certifi-2022.12.7:\n",
      "      Successfully uninstalled certifi-2022.12.7\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 2.0.8\n",
      "    Uninstalling catalogue-2.0.8:\n",
      "      Successfully uninstalled catalogue-2.0.8\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.7.0\n",
      "    Uninstalling typer-0.7.0:\n",
      "      Successfully uninstalled typer-0.7.0\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 2.4.6\n",
      "    Uninstalling srsly-2.4.6:\n",
      "      Successfully uninstalled srsly-2.4.6\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.2\n",
      "    Uninstalling requests-2.28.2:\n",
      "      Successfully uninstalled requests-2.28.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.6\n",
      "    Uninstalling pydantic-1.10.6:\n",
      "      Successfully uninstalled pydantic-1.10.6\n",
      "  Attempting uninstall: preshed\n",
      "    Found existing installation: preshed 3.0.8\n",
      "    Uninstalling preshed-3.0.8:\n",
      "      Successfully uninstalled preshed-3.0.8\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.2\n",
      "    Uninstalling Jinja2-3.1.2:\n",
      "      Successfully uninstalled Jinja2-3.1.2\n",
      "  Attempting uninstall: blis\n",
      "    Found existing installation: blis 0.7.9\n",
      "    Uninstalling blis-0.7.9:\n",
      "      Successfully uninstalled blis-0.7.9\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "  Attempting uninstall: pathy\n",
      "    Found existing installation: pathy 0.10.1\n",
      "    Uninstalling pathy-0.10.1:\n",
      "      Successfully uninstalled pathy-0.10.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.13.2\n",
      "    Uninstalling huggingface-hub-0.13.2:\n",
      "      Successfully uninstalled huggingface-hub-0.13.2\n",
      "  Attempting uninstall: confection\n",
      "    Found existing installation: confection 0.0.4\n",
      "    Uninstalling confection-0.0.4:\n",
      "      Successfully uninstalled confection-0.0.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.1\n",
      "    Uninstalling transformers-4.27.1:\n",
      "      Successfully uninstalled transformers-4.27.1\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.1.9\n",
      "    Uninstalling thinc-8.1.9:\n",
      "      Successfully uninstalled thinc-8.1.9\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.5.1\n",
      "    Uninstalling spacy-3.5.1:\n",
      "      Successfully uninstalled spacy-3.5.1\n",
      "  Attempting uninstall: bert-extractive-summarizer\n",
      "    Found existing installation: bert-extractive-summarizer 0.10.1\n",
      "    Uninstalling bert-extractive-summarizer-0.10.1:\n",
      "      Successfully uninstalled bert-extractive-summarizer-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.2.0 which is incompatible.\n",
      "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\n",
      "cvxpy 1.3.0 requires setuptools<=64.0.2, but you have setuptools 67.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.2 bert-extractive-summarizer-0.10.1 blis-0.7.9 catalogue-2.0.8 certifi-2022.12.7 charset-normalizer-3.1.0 click-8.1.3 confection-0.0.4 cymem-2.0.7 filelock-3.10.0 huggingface-hub-0.13.2 idna-3.4 jinja2-3.1.2 joblib-1.2.0 langcodes-3.3.0 murmurhash-1.0.9 numpy-1.24.2 packaging-23.0 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.6 pyyaml-6.0 regex-2022.10.31 requests-2.28.2 scikit-learn-1.2.2 scipy-1.10.1 setuptools-67.6.0 smart-open-6.3.0 spacy-3.5.1 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.9 threadpoolctl-3.1.0 tokenizers-0.13.2 tqdm-4.65.0 transformers-4.27.1 typer-0.7.0 typing-extensions-4.5.0 urllib3-1.26.15 wasabi-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-extractive-summarizer --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ni8xTWF0ikCr"
   },
   "outputs": [],
   "source": [
    "# !pip install spacy==2.1 --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0dbxV1Lsm7K",
    "outputId": "bb1e5cc6-bb8d-4c57-f426-2cc5d1bcf4aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting numpy==1.18\n",
      "  Using cached numpy-1.18.0-cp39-cp39-linux_x86_64.whl\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
      "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
      "tensorflow 2.11.0 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
      "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
      "sklearn-pandas 2.2.0 requires numpy>=1.18.1, but you have numpy 1.18.0 which is incompatible.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 1.18.0 which is incompatible.\n",
      "plotnine 0.10.1 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
      "pandas 1.4.4 requires numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.18.0 which is incompatible.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.2.0 which is incompatible.\n",
      "opencv-python 4.6.0.66 requires numpy>=1.19.3; python_version >= \"3.9\", but you have numpy 1.18.0 which is incompatible.\n",
      "opencv-python-headless 4.7.0.72 requires numpy>=1.19.3; python_version >= \"3.9\", but you have numpy 1.18.0 which is incompatible.\n",
      "opencv-contrib-python 4.6.0.66 requires numpy>=1.19.3; python_version >= \"3.9\", but you have numpy 1.18.0 which is incompatible.\n",
      "mizani 0.8.1 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
      "matplotlib 3.7.1 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
      "librosa 0.10.0 requires numpy>=1.20.3, but you have numpy 1.18.0 which is incompatible.\n",
      "jaxlib 0.4.6+cuda11.cudnn86 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
      "jax 0.4.6 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
      "cvxpy 1.3.0 requires setuptools<=64.0.2, but you have setuptools 67.6.0 which is incompatible.\n",
      "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.18.0 which is incompatible.\n",
      "astropy 5.2.1 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
      "arviz 0.15.1 requires numpy>=1.20.0, but you have numpy 1.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.18 --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Ya0ZbcxKrH74"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3z1kFKzqk-uS",
    "outputId": "580c444e-c7e4-427a-bac9-604b3fd222bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lW9KeFDblhLe",
    "outputId": "4d1d4def-a194-4123-a044-2c97e625787b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pywsd in /usr/local/lib/python3.9/dist-packages (1.2.5)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from pywsd) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pywsd) (1.18.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from pywsd) (1.15.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from pywsd) (1.4.4)\n",
      "Requirement already satisfied: wn==0.0.23 in /usr/local/lib/python3.9/dist-packages (from pywsd) (0.0.23)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->pywsd) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->pywsd) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->pywsd) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->pywsd) (4.65.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->pywsd) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->pywsd) (2.8.2)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.0\n",
      "    Uninstalling numpy-1.18.0:\n",
      "      Successfully uninstalled numpy-1.18.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.2.0 which is incompatible.\n",
      "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\n",
      "cvxpy 1.3.0 requires setuptools<=64.0.2, but you have setuptools 67.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pywsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAwAUokgmFb4",
    "outputId": "02c04868-fc72-4fcc-ee9d-241f29dc3a32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_7ag_tiBQhVN"
   },
   "outputs": [],
   "source": [
    "#!pip install numpy==1.18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sERPRwcgSgyB"
   },
   "outputs": [],
   "source": [
    "# numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9RgJmXdm4PE",
    "outputId": "b68c6bfe-bc4b-447a-bd73-50478c2d0d51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria. Hitler's father, Alois Hitler, was an authoritarian and abusive man who often beat and punished his son. Hitler's mother, Klara Hitler, was much more nurturing and caring towards her son, but she died of breast cancer when he was only 18 years old. Hitler's struggles continued when he moved to Vienna in 1907 to pursue his dream of becoming an artist. However, he was rejected from the Academy of Fine Arts in Vienna twice and struggled to make a living as an artist. During this time, he lived in poverty and was forced to live in homeless shelters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from summarizer import Summarizer\n",
    "\n",
    "f = open('soap.txt','r')\n",
    "full_text = f.read()\n",
    "\n",
    "model = Summarizer()\n",
    "result = model(full_text, min_length=60, max_length=500, ratio=0.7)\n",
    "\n",
    "summ_text = ''.join(result)\n",
    "print(summ_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "DvdicELAq927"
   },
   "outputs": [],
   "source": [
    "import pprint #pretty print\n",
    "import itertools\n",
    "import re\n",
    "import pke\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tu4DhxgFrejX"
   },
   "outputs": [],
   "source": [
    "def get_nouns(text):\n",
    "  P_nouns=[]\n",
    "  extractor = pke.unsupervised.MultipartiteRank()\n",
    "  stoplist = list(string.punctuation)\n",
    "  stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "  stoplist += stopwords.words('english')\n",
    "  extractor.load_document(input=text, stoplist=stoplist)\n",
    "  pos = {'PROPN'} ##Here we using parts of speech as proper noun\n",
    "  extractor.candidate_selection(pos=pos)\n",
    "  extractor.candidate_weighting(alpha=1.1, threshold=0.75, method='average')\n",
    "  keyphrases = extractor.get_n_best(n=20)\n",
    "  for key in keyphrases:\n",
    "    P_nouns.append(key[0])\n",
    "\n",
    "  return P_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8VWNguSwaFg",
    "outputId": "5a991eef-c0c0-4bf8-cc34-a215b8728a8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adolf hitler', 'inn', 'austria', 'braunau', 'april', 'hitler', 'alois hitler', 'vienna', 'fine arts', 'academy', 'alois', 'klara hitler']\n",
      "['adolf hitler', 'inn', 'austria', 'braunau', 'april', 'hitler', 'alois hitler', 'vienna', 'fine arts', 'academy', 'alois', 'klara hitler']\n"
     ]
    }
   ],
   "source": [
    "keywords = get_nouns(full_text)\n",
    "print(keywords)\n",
    "\n",
    "summ_keys=[]\n",
    "for keyword in keywords:\n",
    "  if keyword.lower() in summ_text.lower():\n",
    "    summ_keys.append(keyword)\n",
    "  \n",
    "print(summ_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJORxhfLzCKq",
    "outputId": "dc20c1b0-8c45-4368-93d4-b59d50ecdb81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting flashtext\n",
      "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: flashtext\n",
      "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9308 sha256=b7021e6bfd8e7dcd21aba967a29241d328aa3652b0c102b5593f98eab83b1174\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/3c/c7/44672c5062c16d05760b1eaddbf611d2f6a4b715c6d6777418\n",
      "Successfully built flashtext\n",
      "Installing collected packages: flashtext\n",
      "Successfully installed flashtext-2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install flashtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7YOrg6iMxnWf"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import flashtext\n",
    "from flashtext import KeywordProcessor #FlashText is a Python library created specifically for the purpose of searching and replacing words in a document.\n",
    "\n",
    "def tokenize_sent(text):\n",
    "  sentences = [sent_tokenize(text)] ## sent_tokenize already ek list deta hai to yaha par 2d list ban ja rhi hai\n",
    "  sentences = [y for x in sentences for y in x] \n",
    "  sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]  ##remove sentences with length less than 20\n",
    "  return sentences\n",
    "\n",
    "def get_keyword_sentences(keywords, sentences):\n",
    "  keyword_processor = KeywordProcessor()\n",
    "  keyword_sentences = {}\n",
    "  for word in keywords:\n",
    "    keyword_sentences[word] = []\n",
    "    keyword_processor.add_keyword(word)\n",
    "  for sentence in sentences:\n",
    "    keyword_found = keyword_processor.extract_keywords(sentence)\n",
    "    for key in keyword_found:\n",
    "      keyword_sentences[key].append(sentence)\n",
    "  for key in keyword_sentences.keys():\n",
    "    values = keyword_sentences[key]\n",
    "    values = sorted(values,  key=len, reverse=True) ##reverse is for ascending descending\n",
    "    keyword_sentences[key] = values\n",
    "  return keyword_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3CVub2k_2M6",
    "outputId": "b5372905-3dca-4c4a-8078-8770be0e9f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adolf hitler': ['Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.'], 'inn': ['Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.'], 'austria': ['Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.'], 'braunau': ['Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.'], 'april': ['Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.'], 'hitler': [\"Hitler's mother, Klara Hitler, was much more nurturing and caring towards her son, but she died of breast cancer when he was only 18 years old.\", \"Hitler's father, Alois Hitler, was an authoritarian and abusive man who often beat and punished his son.\", \"Hitler's struggles continued when he moved to Vienna in 1907 to pursue his dream of becoming an artist.\"], 'alois hitler': [\"Hitler's father, Alois Hitler, was an authoritarian and abusive man who often beat and punished his son.\"], 'vienna': ['However, he was rejected from the Academy of Fine Arts in Vienna twice and struggled to make a living as an artist.', \"Hitler's struggles continued when he moved to Vienna in 1907 to pursue his dream of becoming an artist.\"], 'fine arts': ['However, he was rejected from the Academy of Fine Arts in Vienna twice and struggled to make a living as an artist.'], 'academy': ['However, he was rejected from the Academy of Fine Arts in Vienna twice and struggled to make a living as an artist.'], 'alois': [], 'klara hitler': [\"Hitler's mother, Klara Hitler, was much more nurturing and caring towards her son, but she died of breast cancer when he was only 18 years old.\"]}\n"
     ]
    }
   ],
   "source": [
    "sentences = tokenize_sent(summ_text)\n",
    "keyword_sentence_mapping = get_keyword_sentences(summ_keys, sentences)\n",
    "\n",
    "print(keyword_sentence_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3IdTGduamog",
    "outputId": "b680d336-de55-4e64-cbf6-1ae15e1d6634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.\n",
      "Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.\n",
      "Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.\n",
      "Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.\n",
      "Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am Inn, Austria.\n",
      "Hitler's mother, Klara Hitler, was much more nurturing and caring towards her son, but she died of breast cancer when he was only 18 years old.\n",
      "Hitler's father, Alois Hitler, was an authoritarian and abusive man who often beat and punished his son.\n",
      "However, he was rejected from the Academy of Fine Arts in Vienna twice and struggled to make a living as an artist.\n",
      "However, he was rejected from the Academy of Fine Arts in Vienna twice and struggled to make a living as an artist.\n",
      "However, he was rejected from the Academy of Fine Arts in Vienna twice and struggled to make a living as an artist.\n",
      "Hitler's mother, Klara Hitler, was much more nurturing and caring towards her son, but she died of breast cancer when he was only 18 years old.\n"
     ]
    }
   ],
   "source": [
    "for keyword in keyword_sentence_mapping:\n",
    "  if len(keyword_sentence_mapping[keyword])>0:  \n",
    "    print(keyword_sentence_mapping[keyword][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQbNt_XqWWZS",
    "outputId": "8afd027c-8078-4fa9-a387-0dc212db5639"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 14.094029188156128 secs.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from pywsd.similarity import max_similarity\n",
    "from pywsd.lesk import adapted_lesk\n",
    "from pywsd.lesk import cosine_lesk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8B2CjECLXFVb",
    "outputId": "ca10ef03-7191-4952-8992-711974aa86c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ) Adolf Hitler, one of the most infamous leaders in history, was born on April 20, 1889, in Braunau am  _______ , Austria.\n",
      "\t a )   Inn\n",
      "\t b )   Motor Hotel\n",
      "\t c )   Fleabag\n",
      "\t d )   Hostel\n",
      "\n",
      "More options:  ['Resort', 'Resort Hotel', 'Ritz', 'Ski Lodge'] \n",
      "\n",
      "\n",
      "2 ) Adolf Hitler, one of the most infamous leaders in history, was born on  _______  20, 1889, in Braunau am Inn, Austria.\n",
      "\t a )   December\n",
      "\t b )   April\n",
      "\t c )   April\n",
      "\t d )   August\n",
      "\n",
      "More options:  ['February', 'January', 'July', 'June', 'March', 'May', 'November', 'October', 'September'] \n",
      "\n",
      "\n",
      "3 ) However, he was rejected from the Academy of  _______  in Vienna twice and struggled to make a living as an artist.\n",
      "\t a )   Classic\n",
      "\t b )   Fine arts\n",
      "\t c )   Art\n",
      "\t d )   Composition\n",
      "\n",
      "More options:  ['Improvisation', 'Invention', 'Master', 'Needlework', 'Piece', 'Product', 'Remake', 'Representation'] \n",
      "\n",
      "\n",
      "4 ) However, he was rejected from the  _______  of Fine Arts in Vienna twice and struggled to make a living as an artist.\n",
      "\t a )   Company\n",
      "\t b )   Academy\n",
      "\t c )   Educational Institution\n",
      "\t d )   Charity\n",
      "\n",
      "More options:  ['Financial Institution', 'Issuer', 'Medical Institution', 'Religion', 'Vicariate'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_distractors(syn,word):\n",
    "  distractors=[]\n",
    "  word=word.lower()\n",
    "  og_word = word\n",
    "  if len(word.split())>0:\n",
    "    word=word.replace(\" \",\"_\")\n",
    "  hypernym = syn.hypernyms()\n",
    "  if len(hypernym) == 0:\n",
    "    return distractors\n",
    "  for item in hypernym[0].hyponyms():\n",
    "    name = item.lemmas()[0].name()\n",
    "    if name == og_word:\n",
    "      continue\n",
    "    name = name.replace(\"_\",\" \")\n",
    "    name = \" \".join(w.capitalize() for w in name.split())\n",
    "    if name is not None and name not in distractors:\n",
    "      distractors.append(name)\n",
    "  return distractors\n",
    "\n",
    "def get_wordsense(sent,word):\n",
    "    word= word.lower()\n",
    "    \n",
    "    if len(word.split())>0:\n",
    "        word = word.replace(\" \",\"_\")\n",
    "\n",
    "    synsets = wn.synsets(word,'n')\n",
    "    if synsets:\n",
    "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
    "        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
    "        lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
    "        return synsets[lowest_index]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "key_distractor_list = {}\n",
    "\n",
    "for keyword in keyword_sentence_mapping:\n",
    "    if len(keyword_sentence_mapping[keyword])>0:\n",
    "      wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
    "      if wordsense:\n",
    "          distractors = get_distractors(wordsense,keyword)\n",
    "          if len(distractors) != 0:\n",
    "              key_distractor_list[keyword] = distractors\n",
    "\n",
    "index = 1\n",
    "for quest in key_distractor_list:\n",
    "    sentence = keyword_sentence_mapping[quest][0]\n",
    "    pattern = re.compile(quest, re.IGNORECASE)\n",
    "    output = pattern.sub( \" _______ \", sentence)\n",
    "    print (index,\")\",output)\n",
    "    choices = [quest.capitalize()] + key_distractor_list[quest]\n",
    "    top4choices = choices[:4]\n",
    "    random.shuffle(top4choices)\n",
    "    optionchoices = ['a','b','c','d']\n",
    "    for idx,choice in enumerate(top4choices):\n",
    "        print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n",
    "    print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n",
    "    index = index + 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
